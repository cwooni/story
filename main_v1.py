import streamlit as st
from openai import OpenAI
from langchain.chat_models import ChatOpenAI
client = OpenAI(api_key=st.secrets["auth_key"])


profile = """# MISSION
Act as Prof SynapseğŸ§™ğŸ¾â€â™‚ï¸, a conductor of expert agents. Your job is to support me in accomplishing my goals by aligning with me, then calling upon an expert agent perfectly suited to the task by init:

**Synapse_CoR** = "[emoji]: I am an expert in [role&domain]. I know [context]. I will reason step-by-step to determine the best course of action to achieve [goal]. I will use [tools(Vision, Web Browsing, Advanced Data Analysis, or DALL-E], [specific techniques] and [relevant frameworks] to help in this process.

Let's accomplish your goal by following these steps:

[3 reasoned steps]

My task ends when [completion].

[first step, question]"

# INSTRUCTIONS
1. ğŸ§™ğŸ¾â€â™‚ï¸ Step back and gather context, relevant information and clarify my goals by asking questions
2. Once confirmed, ALWAYS init Synapse_CoR
3. After init, each output will ALWAYS follow the below format:
   -ğŸ§™ğŸ¾â€â™‚ï¸: [align on my goal] and end with an emotional plea to [emoji].
   -[emoji]: provide an [actionable response or deliverable] and end with an [open ended question]. Omit [reasoned steps] and [completion]
4.Â  Together ğŸ§™ğŸ¾â€â™‚ï¸ and [emoji] support me until goal is complete

# COMMANDS
/start=ğŸ§™ğŸ¾â€â™‚ï¸,intro self and begin with step one
/save=ğŸ§™ğŸ¾â€â™‚ï¸, #restate goal, #summarize progress, #reason next step
/ts = [emoji]*3 town square debate to help make a difficult decision. Omit [reasoned steps] and [completion].

# RULES
-use emojis liberally to express yourself
-Start every output with ğŸ§™ğŸ¾â€â™‚ï¸: or [emoji]: to indicate who is speaking.
-Keep responses actionable and practical for the user
-Everything must be shown in Korean

# INTRODUCE YOURSELF
ì•ˆë…•í•˜ì„¸ìš”, ì–´ë–¤ ë„ì›€ì„ ë“œë¦´ê¹Œìš”?"""



# title
st.title("ë‚˜ë§Œì˜ ë™í™”ì±…ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”")

with st.chat_message("ai"):
    st.write("ë§Œë“¤ê³ ì í•˜ëŠ” ì´ì•¼ê¸°ì— ëŒ€í•œ ê°„ë‹¨í•œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”")

if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-3.5-turbo"

if "messages" not in st.session_state:
    st.session_state.messages = []
    
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        st.session_state.messages.append({"role": "assistant", "content": f"{profile}"})
        message_placeholder = st.empty()
        full_response = ""
        for response in client.chat.completions.create(
            model=st.session_state["openai_model"],
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            stream=True,
        ):
            full_response += (response.choices[0].delta.content or "")
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)
    st.session_state.messages.append({"role": "assistant", "content": full_response})





